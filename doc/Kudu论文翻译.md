## Kudu: 支持基于实时数据进行实时分析的存储系统  
![kudu icon](http://getkudu.io/img/logo_small.png)
#### 摘要  
***kudu***是一款支持低延迟随机访问以及高效分析访问方式的开源结构化数据存储引擎. Kudu分布化的数据通过使用横向分片以及对各个分片采用*raft*一致性协议保证副本的方式，提供快速恢复和访问的低延迟. Kudu是在Hadoop的生态系统下被设计出来，支持通过类似Cloundera Impala，Apache Spark，以及MapReduce的工具进行各种方式的访问查询。  
#### 1. 简介
近些年中，随机企业及数据爆炸式的增长与使用，促进了在存储海量数据集上扩展性以及低成本方面的开源技术.尤其Hadoop生态系统已经成为类似大数据解决方案的焦点，因为越来越多传统开源数据存储系统已经未能及时提供一个可扩展的替代品.  

在Hadoop生态系统下选择结构化存储主要有两种方式：面向静态数据集，数据主要通过使用二进制的格式存储在HDFS上，类似的系统包含Apache Avro[^1]
[^1]:Apache Avro. http://avro.apache.org.

或者Apache Parquet[^3]
[^3]:Apache Parquet. http://parquet.apache.org.

，但是即使HDFS或者这些存储格式均未支持单条记录的更新一集高效的随机访问能力.动态数据集惯用类似Apache HBase[^2][^2]:Apache HBase. http://hbase.apache.org.
或者Apache Cassandra[^21][^21]:Apache cassandra.
.这些系统允许低延迟的记录级别读写，但是远远无法满足在类似基于Sql的分析应用或者机器学习应用方面顺序读方面的吞吐需求.  
当同一个应用同时需要，HDFS上静态数据集提供的分析性能和HBase，Cassandra的低延迟行级随机访问能力的话，需要从业人员单独开发复杂的架构.许多Cloudera的用户通过在HBase上做流式的计算更新，接着周期性的通过到处表格到Parquet上做后面的分析. 这种数据流的架构存在诸多的缺点：  
1. 应用架构师需要进行复杂的编码以管理在这两套系统间的数据流与数据同步
2. 运维人员需要管理备份的数据一致，安全策略以及同时监控多个不同的系统
3. 该架构下，会在新数据进入HBase到可被计算分析之间表现出很明显的延迟
4. 现实情况下，系统往往需要通过最近到来的数据对之前已经处理的不可变数据进行修正或者删除. 支持这种操作可能会引入非常高代价的重写，分片数据的替换以及人工干预

Kudu正是这样一种新的存储系统被设计和实现用来填补像HDFS这种高吞吐顺序访问的存储系统和像HBase或者Cassandra这种低延迟随机访问的系统的差距. 当然这些已经存在的系统仍然在某些场景下保持着自己的优势，Kudu提供了一种相对折中的方案替代品，急剧简化了在一些通用场景下的工作量. 特别地，Kudu提供了简单的API给用户进行行级别的增删改操作，以及提供和Parquet吞吐相近的表格扫描.

这片论文介绍了Kudu的架构. 第二章节主要从用户的角度介绍系统的数据模型，所有API以及用户可见的构造. 第三章介绍了Kudu的架构，包含如何分片，在节点间拷贝副本数据，失败恢复以及常见操作的执行逻辑. 第四章讲述了Kudu如何存储单机数据在磁盘上以保证能够在高效数据分析场景下的快速随机访问. 第五章讨论了Kudu与其他Hadoop生态下项目的结合. 第六章展示了在模拟工作负荷情况下的初步性能结果.  

#### 2. 从上层看Kudu
##### 2.1 表格和表格式定义
在用户层面来看，Kudu是支持存储表格结构数据的存储系统. 一个Kudu集群可以包含任意两的表格，每个表格会由一个已经定义好的由一定量的列组成的表定义. 每一列包含列名，字段类型（类似如Int32 或者String等）和可选的空默认值. 其中这些列中的有序子集可以被设定为表格的主建. 主键被强制要求唯一性（对于给定的主键元组最多只能有一行）并在数据行被有效的更新或者删除情况下作为检索数据行的唯一索引. 这种数据模型类似关系型数据库中的数据模型，但是与类似Cassandra，MongoDB[^6]
[^6]: MongoDB

,Riak[^8]
[^8]: Riak 

,BigTable[^12]
[^12]: BigTable

等其他分布式存储系统差别很大.对于一个关系型数据库，用户必须在创建表的同时定义好表的格式定义. 尝试插入一个未定义的列如同违反主键唯一性一样会导致错误的结果. 用户可以任意时间发送一个更新表格的命令去增加或者删除列，当然主键列被限制不能删除.
我们决定为每个列设定上述的数据类型，而不是使用Nosql的方式，一切都是字节`（类似leveldb中的k-v, value为string）`. 主要因为如下亮点：
1. 明确的数据类型允许我们使用类型相关的数据编码方式，例如对整形的字节压缩`（类似leveldb的varint encode） `
2. 明确数据类型允许我们迁移Sql类型的元数据到其他系统，类似通用的业务逻辑或者数据挖掘工具.
与大多数关系型数据库不同，Kudo当前不提供二级索引以及其他非主键的唯一性保证. 尽管我们预期未来的Kudu版本会增加自动的主键生成替代方案，目前的方式需要用户给每个表提前定义好一个主键.
##### 2.2 写操作
创建一个表以后，用户可以通过插入，更新和删除的接口来更新表. 所有接口的使用均需要用户指定主键 － 删除或者更新必须更高层抽象的接口访问机制（详见第五章）.
Kudo提供完整的Java和C++接口，以及试验性的支持Python. 这些接口允许单条而不是批处理的方式，并且支持异步的错误处理以便减少处理大数据操作过程的消耗`（异步处理接口，提高吞吐）`（如数据加载或大量更新）. 目前为止Kudu不支持跨行级事务接口：每个单独的改动操作理论上均执行在自己的事务中，尽管把该改动操作与其他改动操作打包批处理会带来更好的性能. 在同一行中的跨列修改会保证执行的原子性.
##### 2.3 读操作
Kudo对于从表中获取数据仅提供一个扫描操作. 在一次扫描上，用户可以添加任意数量的谓语来过滤结果. 目前为止，我们提供两种类型的谓语：指定列常量值的比较和主键范围的符合. 这些谓语同时被客户端接口与服务端使用，以便有效的减少从磁盘上以及网络上的数据传输量.